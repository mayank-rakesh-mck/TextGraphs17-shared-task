{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7944393,"sourceType":"datasetVersion","datasetId":4671075},{"sourceId":7945212,"sourceType":"datasetVersion","datasetId":4671673},{"sourceId":7998220,"sourceType":"datasetVersion","datasetId":4709560}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e241a04638334d6bbf1e1aadc1cde2ef":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f78c6a8c9d414fc9b2473dd5ceb1617c","IPY_MODEL_d46726082701464cad2038962dbfb042"],"layout":"IPY_MODEL_dcf20f96bcf34faeac3ace17c1f8b64b"}},"f78c6a8c9d414fc9b2473dd5ceb1617c":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5da99887c1a0406bbd341cd97f91f683","placeholder":"​","style":"IPY_MODEL_3ba86d2f2b434315903f3779600320ba","value":"0.020 MB of 0.020 MB uploaded\r"}},"d46726082701464cad2038962dbfb042":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4e1ad2eb0064d988f059afc55ade771","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b97859387db460ea82cbd672f394c26","value":1}},"dcf20f96bcf34faeac3ace17c1f8b64b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5da99887c1a0406bbd341cd97f91f683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ba86d2f2b434315903f3779600320ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4e1ad2eb0064d988f059afc55ade771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b97859387db460ea82cbd672f394c26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom ast import literal_eval\nimport torch_geometric\nfrom torch_geometric.data import Data\nimport networkx as nx\nimport torch\nfrom transformers import GraphormerModel, GraphormerConfig\nfrom transformers import T5EncoderModel\nfrom transformers import T5Tokenizer\nSEED = 42\nimport random\ntorch.manual_seed(SEED)\ntorch.random.manual_seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.cuda.random.manual_seed(SEED)\ntorch.cuda.random.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"bYXieGFeghtF","execution":{"iopub.status.busy":"2024-04-10T07:33:33.309448Z","iopub.execute_input":"2024-04-10T07:33:33.309779Z","iopub.status.idle":"2024-04-10T07:33:34.256459Z","shell.execute_reply.started":"2024-04-10T07:33:33.309753Z","shell.execute_reply":"2024-04-10T07:33:34.255283Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m literal_eval\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"],"ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric'","output_type":"error"}]},{"cell_type":"code","source":"# pip install torch_geometric datasets transformers accelerate","metadata":{"id":"Cv0y55ZJghtG","execution":{"iopub.status.busy":"2024-04-10T06:43:54.857477Z","iopub.execute_input":"2024-04-10T06:43:54.858334Z","iopub.status.idle":"2024-04-10T06:43:54.862662Z","shell.execute_reply.started":"2024-04-10T06:43:54.858300Z","shell.execute_reply":"2024-04-10T06:43:54.861738Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass QuestionAnswerDataset(Dataset):\n\n    def __init__(self, df, tokenizer, max_length, context_key=\"answerEntity\",\n                 tokenizer_truncation=\"only_first\"):\n        super(QuestionAnswerDataset).__init__()\n\n        self.questions = df.question.values\n        self.contexts = df[context_key].values\n        self.labels = torch.tensor(df.correct.values, dtype=torch.float32)#torch.tensor([0]*10961, dtype=torch.float32)##torch.tensor(df.correct.values, dtype=torch.float32)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.tokenized_input = [tokenizer.encode_plus(x, y,\n                              max_length=self.max_length,\n                              padding=\"max_length\",\n                              truncation=tokenizer_truncation,\n                              return_tensors=\"pt\", ) \\\n                          for x, y in zip(self.questions,\n                                          self.contexts)]\n        print(len(self.questions))\n        print(len(self.contexts))\n        print(len(self.labels))\n        assert len(self.questions) == len(self.contexts) == len(self.labels)\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        return {\n                \"input_ids\": self.tokenized_input[idx][\"input_ids\"][0],\n                \"attention_mask\" : self.tokenized_input[idx][\"attention_mask\"][0],\n                \"labels\": self.labels[idx]}","metadata":{"id":"b-qmU-AAghtG","execution":{"iopub.status.busy":"2024-04-10T07:34:12.693986Z","iopub.execute_input":"2024-04-10T07:34:12.694359Z","iopub.status.idle":"2024-04-10T07:34:16.237663Z","shell.execute_reply.started":"2024-04-10T07:34:12.694331Z","shell.execute_reply":"2024-04-10T07:34:16.236803Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"training_data = \"/kaggle/input/kbqa-classification/train.tsv\"#\"/kaggle/input/kbqa-classification/train.tsv\"#\"/kaggle/input/kbqa-classification/train.tsv\"#\"/kaggle/input/kbqa-classification/train.tsv\"\ntrain_data = pd.read_csv(training_data, sep=\"\\t\")\ntrain_data[\"graph\"] = train_data[\"graph\"].apply(eval)\ntrain_data.head(2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"qfuQ9cvgghtG","outputId":"26be27e4-5b8b-4b4f-ac26-49453662c915","execution":{"iopub.status.busy":"2024-04-10T07:34:16.239212Z","iopub.execute_input":"2024-04-10T07:34:16.239678Z","iopub.status.idle":"2024-04-10T07:34:21.855947Z","shell.execute_reply.started":"2024-04-10T07:34:16.239649Z","shell.execute_reply":"2024-04-10T07:34:21.855076Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   sample_id                                           question  \\\n0          0  Whst is the name of the head of state and high...   \n1          1  Whst is the name of the head of state and high...   \n\n  questionEntity                                     answerEntity  \\\n0           Iran               Ruhollah Khomeini's return to Iran   \n1           Iran  Ruhollah Khomeini's letter to Mikhail Gorbachev   \n\n                groundTruthAnswerEntity answerEntityId questionEntityId  \\\n0  Office of the Supreme Leader of Iran       Q7293530             Q794   \n1  Office of the Supreme Leader of Iran       Q5952984             Q794   \n\n  groundTruthAnswerEntityId  correct  \\\n0                 Q16045000    False   \n1                 Q16045000    False   \n\n                                               graph  \n0  {'nodes': [{'type': 'QUESTIONS_ENTITY', 'name_...  \n1  {'nodes': [{'type': 'INTERNAL', 'name_': 'Q417...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>question</th>\n      <th>questionEntity</th>\n      <th>answerEntity</th>\n      <th>groundTruthAnswerEntity</th>\n      <th>answerEntityId</th>\n      <th>questionEntityId</th>\n      <th>groundTruthAnswerEntityId</th>\n      <th>correct</th>\n      <th>graph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Whst is the name of the head of state and high...</td>\n      <td>Iran</td>\n      <td>Ruhollah Khomeini's return to Iran</td>\n      <td>Office of the Supreme Leader of Iran</td>\n      <td>Q7293530</td>\n      <td>Q794</td>\n      <td>Q16045000</td>\n      <td>False</td>\n      <td>{'nodes': [{'type': 'QUESTIONS_ENTITY', 'name_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Whst is the name of the head of state and high...</td>\n      <td>Iran</td>\n      <td>Ruhollah Khomeini's letter to Mikhail Gorbachev</td>\n      <td>Office of the Supreme Leader of Iran</td>\n      <td>Q5952984</td>\n      <td>Q794</td>\n      <td>Q16045000</td>\n      <td>False</td>\n      <td>{'nodes': [{'type': 'INTERNAL', 'name_': 'Q417...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# train_data['correct']=train_data['GT']","metadata":{"execution":{"iopub.status.busy":"2024-04-10T06:44:33.862076Z","iopub.execute_input":"2024-04-10T06:44:33.862423Z","iopub.status.idle":"2024-04-10T06:44:33.866744Z","shell.execute_reply.started":"2024-04-10T06:44:33.862396Z","shell.execute_reply":"2024-04-10T06:44:33.865789Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# graph_json = train_data.iloc[0].graph\n# graph_json['directed']=True\n# nx_graph = nx.node_link_graph(graph_json, )\n","metadata":{"id":"JO7jsJizvDoy","execution":{"iopub.status.busy":"2024-04-10T06:44:34.128038Z","iopub.execute_input":"2024-04-10T06:44:34.128854Z","iopub.status.idle":"2024-04-10T06:44:34.132962Z","shell.execute_reply.started":"2024-04-10T06:44:34.128820Z","shell.execute_reply":"2024-04-10T06:44:34.131991Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# nx_graph","metadata":{"id":"tQ4uV8UxvVC1","execution":{"iopub.status.busy":"2024-04-10T06:44:34.996498Z","iopub.execute_input":"2024-04-10T06:44:34.997265Z","iopub.status.idle":"2024-04-10T06:44:35.001502Z","shell.execute_reply.started":"2024-04-10T06:44:34.997233Z","shell.execute_reply":"2024-04-10T06:44:35.000572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def linearize_graph(graph_dict):\n    nodes = sorted((node_dict for node_dict in graph_dict[\"nodes\"]), key=lambda d:d[\"id\"])\n    for n_id, node_dict in enumerate(nodes):\n        assert n_id == node_dict[\"id\"]\n    src_node_id2links = {}\n    # print(\"graph_dict\", graph_dict)\n    # print(\"links\", graph_dict[\"links\"])\n    for link_dict in graph_dict[\"links\"]:\n        link_src =  link_dict[\"source\"]\n        if src_node_id2links.get(link_src) is None:\n            src_node_id2links[link_src] = []\n        src_node_id2links[link_src].append(link_dict)\n    graph_s = \"\"\n    # print(\"src_node_id2links\", src_node_id2links)\n    for n_id, node_dict in enumerate(nodes):\n        links = src_node_id2links.get(n_id, list())\n        start_label = node_dict[\"label\"]\n        if node_dict[\"type\"] == \"ANSWER_CANDIDATE_ENTITY\":\n            start_label = f\"{SEP_TOKEN} {start_label} {SEP_TOKEN}\"\n        for link_dict in links:\n            target_label = nodes[link_dict[\"target\"]][\"label\"]\n            if nodes[link_dict[\"target\"]][\"type\"] == \"ANSWER_CANDIDATE_ENTITY\":\n                target_label = f\"{SEP_TOKEN} {target_label} {SEP_TOKEN}\"\n            link_s = f\" {start_label}, {link_dict['label']}, {target_label} \"\n            graph_s += link_s\n        # graph_s += node_dict[\"label\"]\n        # print(\"n_id, node_dict\", n_id, node_dict)\n        # if n_id != len(nodes) - 1:\n\n\n        #     link_label = link[\"label\"]\n        #     graph_s += link_label\n    # print('--')\n    return graph_s","metadata":{"id":"y590K3D8ghtH","execution":{"iopub.status.busy":"2024-04-10T06:44:36.034854Z","iopub.execute_input":"2024-04-10T06:44:36.035557Z","iopub.status.idle":"2024-04-10T06:44:36.044629Z","shell.execute_reply.started":"2024-04-10T06:44:36.035528Z","shell.execute_reply":"2024-04-10T06:44:36.043657Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# train_data['qa'] = train_data['question']+\" ; \"+train_data['answerEntity']\ntokenizer = T5Tokenizer.from_pretrained(\"DeepPavlov/t5-wikidata5M-with-neighbors\")#(\"s-nlp/t5_large_ssm_nq_mintaka\")#(\"DeepPavlov/t5-wikidata5M-with-neighbors\")\n# qa_tokens = []\nSEP_TOKEN = tokenizer.sep_token\ntrain_data[\"linearized_graph\"] = train_data[\"graph\"].apply(linearize_graph)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqFR8kCJghtH","outputId":"6318014c-da09-4257-a280-7b8b03d92884","execution":{"iopub.status.busy":"2024-04-10T06:44:37.536950Z","iopub.execute_input":"2024-04-10T06:44:37.537661Z","iopub.status.idle":"2024-04-10T06:44:43.880522Z","shell.execute_reply.started":"2024-04-10T06:44:37.537631Z","shell.execute_reply":"2024-04-10T06:44:43.879720Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f625a900dba41948509a541d9d36452"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3ab22567f774f9f896e559dd2abe6dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4157242e68c4397b34910ce8233900a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606c36b4a4524e6fb91ae3cdf002c155"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8c3aed13cdf4ec29713c475b8c2e513"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[27]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T07:33:28.451024Z","iopub.execute_input":"2024-04-10T07:33:28.451375Z","iopub.status.idle":"2024-04-10T07:33:28.771899Z","shell.execute_reply.started":"2024-04-10T07:33:28.451346Z","shell.execute_reply":"2024-04-10T07:33:28.770652Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m[\u001b[38;5;241m27\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"],"ename":"NameError","evalue":"name 'train_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"train_data['linearized_graph'][27]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T06:44:48.564378Z","iopub.execute_input":"2024-04-10T06:44:48.564748Z","iopub.status.idle":"2024-04-10T06:44:48.571110Z","shell.execute_reply.started":"2024-04-10T06:44:48.564719Z","shell.execute_reply":"2024-04-10T06:44:48.570176Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"' English, on focus list of Wikimedia project, Wikipedia:Vital articles/Level/4  World War I, on focus list of Wikimedia project, Wikipedia:Vital articles/Level/4  [SEP] Franz Ferdinand [SEP], language of work or name, English '"},"metadata":{}}]},{"cell_type":"code","source":"train_data['graph'][27]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T06:45:02.760501Z","iopub.execute_input":"2024-04-10T06:45:02.761165Z","iopub.status.idle":"2024-04-10T06:45:02.768341Z","shell.execute_reply.started":"2024-04-10T06:45:02.761134Z","shell.execute_reply":"2024-04-10T06:45:02.767419Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'nodes': [{'type': 'INTERNAL',\n   'name_': 'Q6173448',\n   'id': 0,\n   'label': 'Wikipedia:Vital articles/Level/4'},\n  {'type': 'INTERNAL', 'name_': 'Q1860', 'id': 1, 'label': 'English'},\n  {'type': 'QUESTIONS_ENTITY',\n   'name_': 'Q361',\n   'id': 2,\n   'label': 'World War I'},\n  {'type': 'ANSWER_CANDIDATE_ENTITY',\n   'name_': 'Q829973',\n   'id': 3,\n   'label': 'Franz Ferdinand'}],\n 'links': [{'name_': 'P5008',\n   'source': 1,\n   'target': 0,\n   'label': 'on focus list of Wikimedia project'},\n  {'name_': 'P5008',\n   'source': 2,\n   'target': 0,\n   'label': 'on focus list of Wikimedia project'},\n  {'name_': 'P407',\n   'source': 3,\n   'target': 1,\n   'label': 'language of work or name'}]}"},"metadata":{}}]},{"cell_type":"code","source":"# model_name=\"sentence-transformers/all-mpnet-base-v2\"\n# from transformers import AutoTokenizer, AutoModel\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# bert_model = AutoModel.from_pretrained(model_name)\n# SEP_TOKEN = tokenizer.sep_token\n# train_data[\"linearized_graph\"] = train_data[\"graph\"].apply(linearize_graph)\n","metadata":{"id":"FwHWIbC0BAzQ","execution":{"iopub.status.busy":"2024-04-01T13:03:58.827834Z","iopub.execute_input":"2024-04-01T13:03:58.828663Z","iopub.status.idle":"2024-04-01T13:03:58.833623Z","shell.execute_reply.started":"2024-04-01T13:03:58.828628Z","shell.execute_reply":"2024-04-01T13:03:58.832585Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"# train_data['correct'] = [0]*10961","metadata":{"id":"-m9_bc6nghtH","execution":{"iopub.status.busy":"2024-04-01T13:03:59.612161Z","iopub.execute_input":"2024-04-01T13:03:59.612910Z","iopub.status.idle":"2024-04-01T13:03:59.618844Z","shell.execute_reply.started":"2024-04-01T13:03:59.612875Z","shell.execute_reply":"2024-04-01T13:03:59.617079Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"code","source":"train_dataset = QuestionAnswerDataset(train_data, tokenizer=tokenizer, max_length=128,context_key=\"linearized_graph\",\n                                      tokenizer_truncation=\"only_second\")\ntrain_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSZK6WLOghtH","outputId":"ca3a7160-4fa7-41eb-85ab-c88613e627bf","execution":{"iopub.status.busy":"2024-04-01T13:05:21.542142Z","iopub.execute_input":"2024-04-01T13:05:21.542480Z","iopub.status.idle":"2024-04-01T13:05:51.240536Z","shell.execute_reply.started":"2024-04-01T13:05:21.542454Z","shell.execute_reply":"2024-04-01T13:05:51.239298Z"},"trusted":true},"execution_count":305,"outputs":[{"name":"stdout","text":"37672\n37672\n37672\n","output_type":"stream"},{"execution_count":305,"output_type":"execute_result","data":{"text/plain":"<__main__.QuestionAnswerDataset at 0x7f469d2308b0>"},"metadata":{}}]},{"cell_type":"code","source":"train_data['qa_tokens']=[dict(item)['input_ids'] for item in train_dataset]","metadata":{"id":"aB6Q2z3zghtI","execution":{"iopub.status.busy":"2024-04-01T13:05:51.242301Z","iopub.execute_input":"2024-04-01T13:05:51.242665Z","iopub.status.idle":"2024-04-01T13:05:52.192620Z","shell.execute_reply.started":"2024-04-01T13:05:51.242627Z","shell.execute_reply":"2024-04-01T13:05:52.191554Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"code","source":"# true_labels_df = train_data[train_data['correct'] ==True].copy()\n# duplicated_true_labels = pd.concat([true_labels_df] * 3, ignore_index=True)\n\n# # Concatenate the original DataFrame and duplicated true labels\n# train_data = pd.concat([train_data, duplicated_true_labels], ignore_index=True)\n# train_data.info()","metadata":{"id":"jl1CwSsUghtI","execution":{"iopub.status.busy":"2024-04-01T12:33:34.294658Z","iopub.execute_input":"2024-04-01T12:33:34.294981Z","iopub.status.idle":"2024-04-01T12:33:34.300760Z","shell.execute_reply.started":"2024-04-01T12:33:34.294944Z","shell.execute_reply":"2024-04-01T12:33:34.299751Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# train_data.to_csv('prep_dataset.csv', index=False)","metadata":{"id":"evron3RqF_z1","execution":{"iopub.status.busy":"2024-04-01T12:33:34.303240Z","iopub.execute_input":"2024-04-01T12:33:34.303582Z","iopub.status.idle":"2024-04-01T12:33:34.312635Z","shell.execute_reply.started":"2024-04-01T12:33:34.303551Z","shell.execute_reply":"2024-04-01T12:33:34.308804Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# # Copyright (c) Microsoft Corporation and HuggingFace\n# # Licensed under the MIT License.\n\nfrom typing import Any, Dict, List, Mapping\n\n\nclass GraphormerDataCollator:\n    def __init__(self, spatial_pos_max=20, on_the_fly_processing=False):\n        # if not is_cython_available():\n            # raise ImportError(\"Graphormer preprocessing needs Cython (pyximport)\")\n\n        self.spatial_pos_max = spatial_pos_max\n        self.on_the_fly_processing = on_the_fly_processing\n\n    def __call__(self, features: List[dict]) -> Dict[str, Any]:\n        # if self.on_the_fly_processing:\n        #     features = [preprocess_item(i) for i in features]\n        try:\n            if not isinstance(features[0], Mapping):\n                features = [vars(f) for f in features]\n            batch = {}\n            max_node_num = max(len(i[\"input_nodes\"]) for i in features)\n            node_feat_size = len(features[0][\"input_nodes\"][0])\n            edge_feat_size = len(features[0][\"attn_edge_type\"][0][0])\n            max_dist = max(len(i[\"input_edges\"][0][0]) for i in features)\n            edge_input_size = len(features[0][\"input_edges\"][0][0][0])\n            batch_size = len(features)\n\n            batch[\"attn_bias\"] = torch.zeros(batch_size, max_node_num + 1, max_node_num + 1, dtype=torch.float)\n            batch[\"attn_edge_type\"] = torch.zeros(batch_size, max_node_num, max_node_num, edge_feat_size, dtype=torch.long)\n            batch[\"spatial_pos\"] = torch.zeros(batch_size, max_node_num, max_node_num, dtype=torch.long)\n            batch[\"in_degree\"] = torch.zeros(batch_size, max_node_num, dtype=torch.long)\n            batch[\"input_nodes\"] = torch.zeros(batch_size, max_node_num, node_feat_size, dtype=torch.long)\n            batch[\"input_edges\"] = torch.zeros(\n                batch_size, max_node_num, max_node_num, max_dist, edge_input_size, dtype=torch.long\n            )\n            batch[\"qa_tokens\"] = torch.zeros(batch_size,1, 128, dtype=torch.int)  # Initialize qa_tokens tensor\n\n            for ix, f in enumerate(features):\n                for k in [\"attn_bias\", \"attn_edge_type\", \"spatial_pos\", \"in_degree\", \"input_nodes\", \"input_edges\", \"qa_tokens\"]:\n                    f[k] = torch.tensor(f[k])\n\n                if len(f[\"attn_bias\"][1:, 1:][f[\"spatial_pos\"] >= self.spatial_pos_max]) > 0:\n                    f[\"attn_bias\"][1:, 1:][f[\"spatial_pos\"] >= self.spatial_pos_max] = float(\"-inf\")\n\n                batch[\"attn_bias\"][ix, : f[\"attn_bias\"].shape[0], : f[\"attn_bias\"].shape[1]] = f[\"attn_bias\"]\n                batch[\"attn_edge_type\"][ix, : f[\"attn_edge_type\"].shape[0], : f[\"attn_edge_type\"].shape[1], :] = f[\n                    \"attn_edge_type\"\n                ]\n                batch[\"spatial_pos\"][ix, : f[\"spatial_pos\"].shape[0], : f[\"spatial_pos\"].shape[1]] = f[\"spatial_pos\"]\n                batch[\"in_degree\"][ix, : f[\"in_degree\"].shape[0]] = f[\"in_degree\"]\n                batch[\"input_nodes\"][ix, : f[\"input_nodes\"].shape[0], :] = f[\"input_nodes\"]\n                batch['qa_tokens'][ix] = f['qa_tokens'][0]\n                batch[\"input_edges\"][\n                    ix, : f[\"input_edges\"].shape[0], : f[\"input_edges\"].shape[1], : f[\"input_edges\"].shape[2], :\n                ] = f[\"input_edges\"]\n\n            batch[\"out_degree\"] = batch[\"in_degree\"]\n    #         batch[\"qa\"]\n            sample = features[0][\"labels\"]\n            if len(sample) == 1:  # one task\n                if isinstance(sample[0], float):  # regression\n                    batch[\"labels\"] = torch.from_numpy(np.concatenate([i[\"labels\"] for i in features]))\n                else:  # binary classification\n                    batch[\"labels\"] = torch.from_numpy(np.concatenate([i[\"labels\"] for i in features]))\n            else:  # multi task classification, left to float to keep the NaNs\n                batch[\"labels\"] = torch.from_numpy(np.stack([i[\"labels\"] for i in features], axis=0))\n\n            return batch\n        except:\n            pass","metadata":{"id":"Lo3Jx1m8ghtI","execution":{"iopub.status.busy":"2024-04-01T13:06:54.448465Z","iopub.execute_input":"2024-04-01T13:06:54.448835Z","iopub.status.idle":"2024-04-01T13:06:54.473885Z","shell.execute_reply.started":"2024-04-01T13:06:54.448804Z","shell.execute_reply":"2024-04-01T13:06:54.472959Z"},"trusted":true},"execution_count":307,"outputs":[]},{"cell_type":"code","source":"# import MultiModalDiscussionTransformer.mDT.src.data.pyg_datasets.pre_processing as p\nfrom transformers.models.graphormer.collating_graphormer import preprocess_item #GraphormerDataCollator\n# from MultiModalDiscussionTransformer.mDT.src.data import algos # import floyd_warshall, gen_edge_input  # Import Cython functions\nimport numpy as np\nimport json\n\ndef json_graph_to_pyg_data(G, graph_json):\n    # Create a NetworkX graph from the JSON data\n    # G = nx.Graph()\n\n    # # Add nodes with features\n    # for node in json_graph['nodes']:\n    #     G.add_node(node['id'], type=node['type'], name=node['name_'], label=node['label'])\n\n    # # Add edges with attributes\n    # for link in json_graph['links']:\n    #     G.add_edge(link['source'], link['target'], name=link['name_'], label=link['label'])\n    # G = nx.node_link_graph(graph_json, )\n    # Convert NetworkX graph to PyTorch Geometric data\n    edges = torch.tensor(list(G.edges()), dtype=torch.long).t().contiguous()\n    # print(edges)\n    edge_label_map = {label: idx for idx, label in enumerate(set(link['label'] for link in graph_json['links']))}\n    # print(edge_label_map)\n    edge_attrs = torch.tensor([edge_label_map[G[u][v][0]['label']] for u, v in list(G.edges())], dtype=torch.long).unsqueeze(1)\n\n    # print(edge_attrs)\n    x = torch.tensor([[node['id']] for node in graph_json['nodes']], dtype=torch.float)  # Using node IDs as features\n\n    dist_matrix = np.zeros((len(G.nodes), len(G.nodes)), dtype=np.float32)\n    for u, v, d in G.edges(data=True):\n        dist_matrix[u][v] = 1  # For non-weighted graph, set distance as 1\n\n    for i in range(len(G.nodes)):\n        dist_matrix[i][i] = 0  # Diagonal elements\n\n    dist_matrix = nx.floyd_warshall_numpy(G, weight=None)\n    data = Data(node_feat=x, edge_index=edges, edge_attr=edge_attrs, distance_matrix=[dist_matrix], num_nodes = x.size(0), y=[0])\n\n    return data","metadata":{"id":"dPvY8eK8ghtI","execution":{"iopub.status.busy":"2024-04-01T13:06:54.804076Z","iopub.execute_input":"2024-04-01T13:06:54.804435Z","iopub.status.idle":"2024-04-01T13:06:54.819245Z","shell.execute_reply.started":"2024-04-01T13:06:54.804405Z","shell.execute_reply":"2024-04-01T13:06:54.818010Z"},"trusted":true},"execution_count":308,"outputs":[]},{"cell_type":"code","source":"# Mine\nfrom tqdm import tqdm\ndataset = []\nindexes = []\nfor ind, item in tqdm(train_data.iterrows()):\n    try:\n        graph_json = item.graph\n        graph_json[\"directed\"] = True\n        G = nx.node_link_graph(graph_json, )\n\n        data = json_graph_to_pyg_data(G, graph_json)\n        data=preprocess_item(data)\n#         print(data)\n#         print(item.qa_tokens)\n        data['qa_tokens'] = item.qa_tokens\n        data.y =[1 if item.correct==True else 0]\n        # data  = preprocess_item(data)\n        for key in data.keys():\n            data[key] = torch.tensor(data[key])\n            data[key] = data[key].unsqueeze(0)\n        dataset.append(data)\n    except:\n        print(ind)\n        indexes.append(ind)\n#         dataset.append(Data(x=[0]))\n        pass","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALa6kvLCghtI","outputId":"acc3a6b0-5659-4ed0-d4fc-cdbc9c5345a2","execution":{"iopub.status.busy":"2024-04-01T13:08:41.926300Z","iopub.execute_input":"2024-04-01T13:08:41.926770Z","iopub.status.idle":"2024-04-01T13:09:43.147276Z","shell.execute_reply.started":"2024-04-01T13:08:41.926731Z","shell.execute_reply":"2024-04-01T13:09:43.145334Z"},"trusted":true},"execution_count":315,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]/tmp/ipykernel_34/1209831208.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  data[key] = torch.tensor(data[key])\n319it [00:00, 649.92it/s]","output_type":"stream"},{"name":"stdout","text":"190\n","output_type":"stream"},{"name":"stderr","text":"2152it [00:03, 689.20it/s]","output_type":"stream"},{"name":"stdout","text":"2072\n","output_type":"stream"},{"name":"stderr","text":"2439it [00:03, 705.10it/s]","output_type":"stream"},{"name":"stdout","text":"2337\n","output_type":"stream"},{"name":"stderr","text":"4655it [00:07, 593.15it/s]","output_type":"stream"},{"name":"stdout","text":"4549\n","output_type":"stream"},{"name":"stderr","text":"6189it [00:09, 678.42it/s]","output_type":"stream"},{"name":"stdout","text":"6068\n","output_type":"stream"},{"name":"stderr","text":"7224it [00:11, 694.47it/s]","output_type":"stream"},{"name":"stdout","text":"7148\n7215\n","output_type":"stream"},{"name":"stderr","text":"7581it [00:11, 682.45it/s]","output_type":"stream"},{"name":"stdout","text":"7478\n","output_type":"stream"},{"name":"stderr","text":"8055it [00:12, 651.16it/s]","output_type":"stream"},{"name":"stdout","text":"7944\n","output_type":"stream"},{"name":"stderr","text":"9161it [00:14, 654.76it/s]","output_type":"stream"},{"name":"stdout","text":"9042\n","output_type":"stream"},{"name":"stderr","text":"12272it [00:18, 642.50it/s]","output_type":"stream"},{"name":"stdout","text":"12206\n","output_type":"stream"},{"name":"stderr","text":"12649it [00:19, 598.56it/s]","output_type":"stream"},{"name":"stdout","text":"12578\n12619\n","output_type":"stream"},{"name":"stderr","text":"13037it [00:20, 633.49it/s]","output_type":"stream"},{"name":"stdout","text":"12911\n","output_type":"stream"},{"name":"stderr","text":"13754it [00:21, 645.60it/s]","output_type":"stream"},{"name":"stdout","text":"13665\n13744\n13766\n","output_type":"stream"},{"name":"stderr","text":"13897it [00:21, 646.04it/s]","output_type":"stream"},{"name":"stdout","text":"13811\n13834\n13871\n13888\n","output_type":"stream"},{"name":"stderr","text":"15664it [00:24, 617.64it/s]","output_type":"stream"},{"name":"stdout","text":"15589\n","output_type":"stream"},{"name":"stderr","text":"16455it [00:25, 674.79it/s]","output_type":"stream"},{"name":"stdout","text":"16354\n","output_type":"stream"},{"name":"stderr","text":"17110it [00:26, 624.55it/s]","output_type":"stream"},{"name":"stdout","text":"17005\n","output_type":"stream"},{"name":"stderr","text":"18322it [00:31, 532.16it/s]","output_type":"stream"},{"name":"stdout","text":"18203\n","output_type":"stream"},{"name":"stderr","text":"18668it [00:31, 647.18it/s]","output_type":"stream"},{"name":"stdout","text":"18563\n18574\n18585\n","output_type":"stream"},{"name":"stderr","text":"19585it [00:33, 653.65it/s]","output_type":"stream"},{"name":"stdout","text":"19459\n19481\n19493\n19503\n19574\n","output_type":"stream"},{"name":"stderr","text":"19801it [00:33, 692.87it/s]","output_type":"stream"},{"name":"stdout","text":"19660\n","output_type":"stream"},{"name":"stderr","text":"19938it [00:33, 657.91it/s]","output_type":"stream"},{"name":"stdout","text":"19825\n","output_type":"stream"},{"name":"stderr","text":"21129it [00:35, 625.94it/s]","output_type":"stream"},{"name":"stdout","text":"21011\n21113\n","output_type":"stream"},{"name":"stderr","text":"21261it [00:35, 638.84it/s]","output_type":"stream"},{"name":"stdout","text":"21173\n21186\n21207\n21237\n","output_type":"stream"},{"name":"stderr","text":"21394it [00:35, 642.84it/s]","output_type":"stream"},{"name":"stdout","text":"21310\n","output_type":"stream"},{"name":"stderr","text":"22088it [00:37, 652.94it/s]","output_type":"stream"},{"name":"stdout","text":"22000\n22043\n22063\n22086\n22109\n","output_type":"stream"},{"name":"stderr","text":"22221it [00:37, 634.73it/s]","output_type":"stream"},{"name":"stdout","text":"22151\n22179\n","output_type":"stream"},{"name":"stderr","text":"22806it [00:38, 645.69it/s]","output_type":"stream"},{"name":"stdout","text":"22729\n22837\n","output_type":"stream"},{"name":"stderr","text":"23403it [00:39, 649.29it/s]","output_type":"stream"},{"name":"stdout","text":"23287\n23303\n23359\n","output_type":"stream"},{"name":"stderr","text":"24138it [00:40, 575.23it/s]","output_type":"stream"},{"name":"stdout","text":"24060\n","output_type":"stream"},{"name":"stderr","text":"24826it [00:41, 599.04it/s]","output_type":"stream"},{"name":"stdout","text":"24744\n24756\n","output_type":"stream"},{"name":"stderr","text":"25292it [00:42, 642.96it/s]","output_type":"stream"},{"name":"stdout","text":"25194\n","output_type":"stream"},{"name":"stderr","text":"26209it [00:43, 650.43it/s]","output_type":"stream"},{"name":"stdout","text":"26120\n26171\n","output_type":"stream"},{"name":"stderr","text":"26345it [00:43, 656.67it/s]","output_type":"stream"},{"name":"stdout","text":"26274\n26304\n","output_type":"stream"},{"name":"stderr","text":"27251it [00:45, 624.88it/s]","output_type":"stream"},{"name":"stdout","text":"27127\n27138\n27233\n","output_type":"stream"},{"name":"stderr","text":"27446it [00:45, 639.03it/s]","output_type":"stream"},{"name":"stdout","text":"27363\n27376\n","output_type":"stream"},{"name":"stderr","text":"27700it [00:45, 617.79it/s]","output_type":"stream"},{"name":"stdout","text":"27581\n27604\n27662\n","output_type":"stream"},{"name":"stderr","text":"27976it [00:46, 670.99it/s]","output_type":"stream"},{"name":"stdout","text":"27901\n","output_type":"stream"},{"name":"stderr","text":"28518it [00:47, 631.65it/s]","output_type":"stream"},{"name":"stdout","text":"28425\n","output_type":"stream"},{"name":"stderr","text":"28782it [00:47, 634.85it/s]","output_type":"stream"},{"name":"stdout","text":"28657\n","output_type":"stream"},{"name":"stderr","text":"29131it [00:48, 690.48it/s]","output_type":"stream"},{"name":"stdout","text":"29051\n29059\n29072\n29139\n29149\n","output_type":"stream"},{"name":"stderr","text":"29343it [00:48, 696.06it/s]","output_type":"stream"},{"name":"stdout","text":"29209\n29229\n29260\n29296\n29305\n","output_type":"stream"},{"name":"stderr","text":"29697it [00:48, 683.20it/s]","output_type":"stream"},{"name":"stdout","text":"29571\n29645\n29669\n","output_type":"stream"},{"name":"stderr","text":"30525it [00:50, 627.75it/s]","output_type":"stream"},{"name":"stdout","text":"30406\n","output_type":"stream"},{"name":"stderr","text":"30913it [00:50, 639.27it/s]","output_type":"stream"},{"name":"stdout","text":"30815\n","output_type":"stream"},{"name":"stderr","text":"31122it [00:51, 671.93it/s]","output_type":"stream"},{"name":"stdout","text":"31037\n31103\n31129\n31169\n","output_type":"stream"},{"name":"stderr","text":"31259it [00:51, 673.76it/s]","output_type":"stream"},{"name":"stdout","text":"31178\n","output_type":"stream"},{"name":"stderr","text":"31607it [00:51, 682.04it/s]","output_type":"stream"},{"name":"stdout","text":"31520\n","output_type":"stream"},{"name":"stderr","text":"32104it [00:52, 684.13it/s]","output_type":"stream"},{"name":"stdout","text":"32030\n","output_type":"stream"},{"name":"stderr","text":"32315it [00:52, 687.67it/s]","output_type":"stream"},{"name":"stdout","text":"32232\n32236\n","output_type":"stream"},{"name":"stderr","text":"32657it [00:53, 665.31it/s]","output_type":"stream"},{"name":"stdout","text":"32529\n","output_type":"stream"},{"name":"stderr","text":"32798it [00:53, 683.96it/s]","output_type":"stream"},{"name":"stdout","text":"32676\n32708\n32756\n32773\n","output_type":"stream"},{"name":"stderr","text":"33005it [00:53, 681.70it/s]","output_type":"stream"},{"name":"stdout","text":"32874\n32895\n32973\n32983\n33009\n","output_type":"stream"},{"name":"stderr","text":"33148it [00:54, 690.43it/s]","output_type":"stream"},{"name":"stdout","text":"33046\n","output_type":"stream"},{"name":"stderr","text":"33495it [00:54, 672.18it/s]","output_type":"stream"},{"name":"stdout","text":"33401\n","output_type":"stream"},{"name":"stderr","text":"33848it [00:55, 698.07it/s]","output_type":"stream"},{"name":"stdout","text":"33750\n33760\n","output_type":"stream"},{"name":"stderr","text":"34290it [00:55, 723.41it/s]","output_type":"stream"},{"name":"stdout","text":"34157\n34178\n","output_type":"stream"},{"name":"stderr","text":"34434it [00:56, 679.52it/s]","output_type":"stream"},{"name":"stdout","text":"34351\n34393\n34439\n34477\n","output_type":"stream"},{"name":"stderr","text":"34717it [00:56, 700.40it/s]","output_type":"stream"},{"name":"stdout","text":"34577\n34586\n","output_type":"stream"},{"name":"stderr","text":"35073it [00:56, 677.42it/s]","output_type":"stream"},{"name":"stdout","text":"35004\n35049\n35065\n35092\n35120\n","output_type":"stream"},{"name":"stderr","text":"35283it [00:57, 687.89it/s]","output_type":"stream"},{"name":"stdout","text":"35144\n35153\n35166\n35195\n","output_type":"stream"},{"name":"stderr","text":"35985it [00:58, 563.54it/s]","output_type":"stream"},{"name":"stdout","text":"35919\n","output_type":"stream"},{"name":"stderr","text":"36249it [00:58, 640.79it/s]","output_type":"stream"},{"name":"stdout","text":"36128\n","output_type":"stream"},{"name":"stderr","text":"36778it [00:59, 612.94it/s]","output_type":"stream"},{"name":"stdout","text":"36664\n","output_type":"stream"},{"name":"stderr","text":"37672it [01:01, 615.49it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch_geometric.loader import DataLoader\ndata_collator=GraphormerDataCollator()\nloader = DataLoader(dataset, batch_size=1, collate_fn=data_collator, shuffle=False)","metadata":{"id":"NdJQ6wJrghtJ","execution":{"iopub.status.busy":"2024-04-01T13:10:13.834472Z","iopub.execute_input":"2024-04-01T13:10:13.834831Z","iopub.status.idle":"2024-04-01T13:10:13.841522Z","shell.execute_reply.started":"2024-04-01T13:10:13.834802Z","shell.execute_reply":"2024-04-01T13:10:13.840367Z"},"trusted":true},"execution_count":316,"outputs":[]},{"cell_type":"code","source":"len(loader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cculG091vQN","outputId":"63dcef1d-2bdd-4d57-9432-8c4383e1547e","execution":{"iopub.status.busy":"2024-04-01T13:10:14.329152Z","iopub.execute_input":"2024-04-01T13:10:14.329496Z","iopub.status.idle":"2024-04-01T13:10:14.337439Z","shell.execute_reply.started":"2024-04-01T13:10:14.329464Z","shell.execute_reply":"2024-04-01T13:10:14.336282Z"},"trusted":true},"execution_count":317,"outputs":[{"execution_count":317,"output_type":"execute_result","data":{"text/plain":"37541"},"metadata":{}}]},{"cell_type":"code","source":"generator1 = torch.Generator().manual_seed(SEED)\ntest_dataset, dev_dataset = torch.utils.data.random_split(dataset, [3700, 33841], generator=generator1)","metadata":{"id":"LRJo5AHdghtJ","execution":{"iopub.status.busy":"2024-04-01T13:10:15.367349Z","iopub.execute_input":"2024-04-01T13:10:15.367705Z","iopub.status.idle":"2024-04-01T13:10:15.378742Z","shell.execute_reply.started":"2024-04-01T13:10:15.367676Z","shell.execute_reply":"2024-04-01T13:10:15.377449Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dev_dataset, batch_size=1, collate_fn=data_collator, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1, collate_fn=data_collator, shuffle=False)","metadata":{"id":"iihidF4TghtJ","execution":{"iopub.status.busy":"2024-04-01T13:10:22.415844Z","iopub.execute_input":"2024-04-01T13:10:22.416576Z","iopub.status.idle":"2024-04-01T13:10:22.423439Z","shell.execute_reply.started":"2024-04-01T13:10:22.416543Z","shell.execute_reply":"2024-04-01T13:10:22.422337Z"},"trusted":true},"execution_count":319,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict\ndataset_dict = DatasetDict({'train': dataset}, )","metadata":{"id":"E_LjMqyqghtJ","execution":{"iopub.status.busy":"2024-04-01T09:22:19.577230Z","iopub.execute_input":"2024-04-01T09:22:19.577633Z","iopub.status.idle":"2024-04-01T09:22:20.792773Z","shell.execute_reply.started":"2024-04-01T09:22:19.577599Z","shell.execute_reply":"2024-04-01T09:22:20.791981Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AttentionPooling(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(AttentionPooling, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n        self.attention_weights = nn.Linear(hidden_size, 1)\n\n    def forward(self, last_hidden_state):\n        # Apply linear transformation to obtain attention scores\n        attention_scores = self.attention_weights(torch.tanh(self.linear(last_hidden_state)))\n\n        # Apply softmax to get attention weights\n        attention_weights = F.softmax(attention_scores, dim=0)\n\n        # Apply attention weights to node embeddings and sum to get graph embedding\n        graph_embedding = torch.sum(torch.mul(last_hidden_state, attention_weights), dim=0)\n\n        return graph_embedding\n\n\nclass InterHead(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.text_fc = nn.Linear(hidden_dim, hidden_dim, bias=False)\n        self.graph_fc = nn.Linear(hidden_dim, hidden_dim, bias=False)\n        self.softmax = nn.Softmax(dim=0)\n        self.atn_layer = AttentionPooling(input_size=512, hidden_size=512)\n\n    def forward(self, text, graph):\n        # text = torch.mean(text[0], dim=0)\n        # graph = self.atn_layer(graph[0])\n        text_sen = self.text_fc(text)\n        graph_sen = self.graph_fc(graph)\n\n        a_tt = torch.mul(text, text_sen).sum(-1)\n        a_tg = torch.mul(text, graph_sen).sum(-1)\n        a_gt = torch.mul(graph, text_sen).sum(-1)\n        a_gg = torch.mul(graph, graph_sen).sum(-1)\n\n        a_tt, a_tg = self.softmax(torch.stack([a_tt, a_tg])).split([1, 1], dim=0)\n        a_gt, a_gg = self.softmax(torch.stack([a_gt, a_gg])).split([1, 1], dim=0)\n\n        a_tt = a_tt.squeeze(0).unsqueeze(-1)\n        a_tg = a_tg.squeeze(0).unsqueeze(-1)\n        a_gt = a_gt.squeeze(0).unsqueeze(-1)\n        a_gg = a_gg.squeeze(0).unsqueeze(-1)\n\n        text = torch.mul(a_tt, text) + torch.mul(a_tg, graph)\n        graph = torch.mul(a_gt, text) + torch.mul(a_gg, graph)\n        return text, graph\n\nclass TextModule(nn.Module):\n    def __init__(self):\n        super().__init__()\n        T5EncoderModel._keys_to_ignore_on_load_unexpected = [\"decoder.*\"]\n        self.auto_model = T5EncoderModel.from_pretrained(\"DeepPavlov/t5-wikidata5M-with-neighbors\")\n        self.tokenizer = T5Tokenizer.from_pretrained(\"DeepPavlov/t5-wikidata5M-with-neighbors\")\n        # self.auto_model = bert_model\n    def forward(self, inputs):\n        hidden_state = self.auto_model(inputs)\n        return hidden_state['last_hidden_state']\n\n\nclass GraphormerModule(nn.Module):\n    def __init__(self):\n        super().__init__()\n        config = GraphormerConfig(embedding_dim=512)\n        self.model = GraphormerModel.from_pretrained(\"clefourrier/pcqm4mv2_graphormer_base\", ignore_mismatched_sizes=True,config=config )\n#         for layer in self.model.children():\n#             if hasattr(layer, 'reset_parameters'):\n#                 layer.reset_parameters()\n    def forward(self, input_nodes, input_edges, attn_bias, in_degree, out_degree, spatial_pos, attn_edge_type):\n        graph_encoding = self.model(input_nodes, input_edges, attn_bias, in_degree, out_degree, spatial_pos, attn_edge_type)\n        outputs, hidden_states = graph_encoding[\"last_hidden_state\"], graph_encoding[\"hidden_states\"]\n        return outputs, hidden_states\n\nclass T5GrapormerInteractModel(nn.Module):\n    def __init__(self, layers=10, dropout=0.1):\n        super().__init__()\n        # self.layers=layers\n        # self.dropout=droput\n        self.text_encoder = TextModule()\n        self.graph_encoder = GraphormerModule()\n        for param in self.text_encoder.parameters():\n            param.requires_grad = True\n        for param in self.graph_encoder.parameters():\n            param.requires_grad = True\n        self.inter = nn.ModuleList()\n        for i in range(10):\n            self.inter.append(InterHead(hidden_dim=512))\n        self.cls = nn.Linear(512, 1)\n        self.act_func = nn.ReLU()\n        self.dropout = nn.Dropout(0.1)\n        # self.dense = nn.linear(512, 512)\n        self.fc = nn.Linear(2 * 512, 512)\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.1),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.Dropout(p=0.1),\n            nn.ReLU(),\n            nn.Linear(512, 1),\n        )\n        self.atn_layer=AttentionPooling(input_size=512, hidden_size=512)\n    def forward(self, inputs):\n        text_rep = self.text_encoder(inputs['qa_tokens'])\n        # print(text_rep)\n        graph_rep, _ = self.graph_encoder(torch.tensor(inputs['input_nodes']), torch.tensor(inputs['input_edges']), torch.tensor(inputs['attn_bias']), torch.tensor(inputs['in_degree']), torch.tensor(inputs['out_degree']), torch.tensor(inputs['spatial_pos']), torch.tensor(inputs['attn_edge_type']))\n        # print(graph_rep)\n#         print(text_rep, graph_rep)\n        text_rep = torch.stack([elem[0, :] for elem in text_rep])#torch.stack([elem[0, :] for elem in text_rep])\n        graph_rep = torch.stack([elem[0, :] for elem in graph_rep])#torch.stack([elem[0, :] for elem in graph_rep])\n        org_text_rep = text_rep\n        org_graph_rep = graph_rep\n        for i in range(10-1):\n            text_rep, graph_rep = self.inter[i](text_rep, graph_rep)\n#         print(text_rep, graph_rep)\n        text_code = org_text_rep+text_rep#torch.mul(org_text_rep, text_rep)\n        graph_code = org_text_rep+graph_rep#torch.mul(org_graph_rep,graph_rep)\n        text_code = self.dropout(self.act_func(text_code))\n        graph_code = self.dropout(self.act_func(graph_code))\n        rep = torch.cat([text_code,\n                             graph_code],dim=-1)\n#         print(rep)\n        rep = self.act_func(self.dropout(self.fc(rep)))\n        class_logits = self.classifier(rep)\n#         class_logits = torch.sigmoid(class_logits)\n        return class_logits\n\n\n\n\n","metadata":{"id":"d-lYsFyHghtJ","execution":{"iopub.status.busy":"2024-04-01T13:10:25.810117Z","iopub.execute_input":"2024-04-01T13:10:25.810520Z","iopub.status.idle":"2024-04-01T13:10:25.851132Z","shell.execute_reply.started":"2024-04-01T13:10:25.810478Z","shell.execute_reply":"2024-04-01T13:10:25.849910Z"},"trusted":true},"execution_count":320,"outputs":[]},{"cell_type":"code","source":"interact_model = T5GrapormerInteractModel()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9mxFr5fghtJ","outputId":"3ad88b49-435e-480c-c527-43306b401216","execution":{"iopub.status.busy":"2024-04-01T13:11:19.934850Z","iopub.execute_input":"2024-04-01T13:11:19.935193Z","iopub.status.idle":"2024-04-01T13:11:21.822399Z","shell.execute_reply.started":"2024-04-01T13:11:19.935161Z","shell.execute_reply":"2024-04-01T13:11:21.821443Z"},"trusted":true},"execution_count":324,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of GraphormerModel were not initialized from the model checkpoint at clefourrier/pcqm4mv2_graphormer_base and are newly initialized: ['graph_encoder.graph_attn_bias.edge_dis_encoder.weight', 'graph_encoder.graph_attn_bias.edge_encoder.weight', 'graph_encoder.graph_attn_bias.graph_token_virtual_distance.weight', 'graph_encoder.graph_attn_bias.spatial_pos_encoder.weight', 'graph_encoder.graph_node_feature.atom_encoder.weight', 'graph_encoder.graph_node_feature.graph_token.weight', 'graph_encoder.graph_node_feature.in_degree_encoder.weight', 'graph_encoder.graph_node_feature.out_degree_encoder.weight', 'graph_encoder.layers.0.fc1.bias', 'graph_encoder.layers.0.fc1.weight', 'graph_encoder.layers.0.fc2.bias', 'graph_encoder.layers.0.fc2.weight', 'graph_encoder.layers.0.final_layer_norm.bias', 'graph_encoder.layers.0.final_layer_norm.weight', 'graph_encoder.layers.0.self_attn.k_proj.bias', 'graph_encoder.layers.0.self_attn.k_proj.weight', 'graph_encoder.layers.0.self_attn.out_proj.bias', 'graph_encoder.layers.0.self_attn.out_proj.weight', 'graph_encoder.layers.0.self_attn.q_proj.bias', 'graph_encoder.layers.0.self_attn.q_proj.weight', 'graph_encoder.layers.0.self_attn.v_proj.bias', 'graph_encoder.layers.0.self_attn.v_proj.weight', 'graph_encoder.layers.0.self_attn_layer_norm.bias', 'graph_encoder.layers.0.self_attn_layer_norm.weight', 'graph_encoder.layers.1.fc1.bias', 'graph_encoder.layers.1.fc1.weight', 'graph_encoder.layers.1.fc2.bias', 'graph_encoder.layers.1.fc2.weight', 'graph_encoder.layers.1.final_layer_norm.bias', 'graph_encoder.layers.1.final_layer_norm.weight', 'graph_encoder.layers.1.self_attn.k_proj.bias', 'graph_encoder.layers.1.self_attn.k_proj.weight', 'graph_encoder.layers.1.self_attn.out_proj.bias', 'graph_encoder.layers.1.self_attn.out_proj.weight', 'graph_encoder.layers.1.self_attn.q_proj.bias', 'graph_encoder.layers.1.self_attn.q_proj.weight', 'graph_encoder.layers.1.self_attn.v_proj.bias', 'graph_encoder.layers.1.self_attn.v_proj.weight', 'graph_encoder.layers.1.self_attn_layer_norm.bias', 'graph_encoder.layers.1.self_attn_layer_norm.weight', 'graph_encoder.layers.10.fc1.bias', 'graph_encoder.layers.10.fc1.weight', 'graph_encoder.layers.10.fc2.bias', 'graph_encoder.layers.10.fc2.weight', 'graph_encoder.layers.10.final_layer_norm.bias', 'graph_encoder.layers.10.final_layer_norm.weight', 'graph_encoder.layers.10.self_attn.k_proj.bias', 'graph_encoder.layers.10.self_attn.k_proj.weight', 'graph_encoder.layers.10.self_attn.out_proj.bias', 'graph_encoder.layers.10.self_attn.out_proj.weight', 'graph_encoder.layers.10.self_attn.q_proj.bias', 'graph_encoder.layers.10.self_attn.q_proj.weight', 'graph_encoder.layers.10.self_attn.v_proj.bias', 'graph_encoder.layers.10.self_attn.v_proj.weight', 'graph_encoder.layers.10.self_attn_layer_norm.bias', 'graph_encoder.layers.10.self_attn_layer_norm.weight', 'graph_encoder.layers.11.fc1.bias', 'graph_encoder.layers.11.fc1.weight', 'graph_encoder.layers.11.fc2.bias', 'graph_encoder.layers.11.fc2.weight', 'graph_encoder.layers.11.final_layer_norm.bias', 'graph_encoder.layers.11.final_layer_norm.weight', 'graph_encoder.layers.11.self_attn.k_proj.bias', 'graph_encoder.layers.11.self_attn.k_proj.weight', 'graph_encoder.layers.11.self_attn.out_proj.bias', 'graph_encoder.layers.11.self_attn.out_proj.weight', 'graph_encoder.layers.11.self_attn.q_proj.bias', 'graph_encoder.layers.11.self_attn.q_proj.weight', 'graph_encoder.layers.11.self_attn.v_proj.bias', 'graph_encoder.layers.11.self_attn.v_proj.weight', 'graph_encoder.layers.11.self_attn_layer_norm.bias', 'graph_encoder.layers.11.self_attn_layer_norm.weight', 'graph_encoder.layers.2.fc1.bias', 'graph_encoder.layers.2.fc1.weight', 'graph_encoder.layers.2.fc2.bias', 'graph_encoder.layers.2.fc2.weight', 'graph_encoder.layers.2.final_layer_norm.bias', 'graph_encoder.layers.2.final_layer_norm.weight', 'graph_encoder.layers.2.self_attn.k_proj.bias', 'graph_encoder.layers.2.self_attn.k_proj.weight', 'graph_encoder.layers.2.self_attn.out_proj.bias', 'graph_encoder.layers.2.self_attn.out_proj.weight', 'graph_encoder.layers.2.self_attn.q_proj.bias', 'graph_encoder.layers.2.self_attn.q_proj.weight', 'graph_encoder.layers.2.self_attn.v_proj.bias', 'graph_encoder.layers.2.self_attn.v_proj.weight', 'graph_encoder.layers.2.self_attn_layer_norm.bias', 'graph_encoder.layers.2.self_attn_layer_norm.weight', 'graph_encoder.layers.3.fc1.bias', 'graph_encoder.layers.3.fc1.weight', 'graph_encoder.layers.3.fc2.bias', 'graph_encoder.layers.3.fc2.weight', 'graph_encoder.layers.3.final_layer_norm.bias', 'graph_encoder.layers.3.final_layer_norm.weight', 'graph_encoder.layers.3.self_attn.k_proj.bias', 'graph_encoder.layers.3.self_attn.k_proj.weight', 'graph_encoder.layers.3.self_attn.out_proj.bias', 'graph_encoder.layers.3.self_attn.out_proj.weight', 'graph_encoder.layers.3.self_attn.q_proj.bias', 'graph_encoder.layers.3.self_attn.q_proj.weight', 'graph_encoder.layers.3.self_attn.v_proj.bias', 'graph_encoder.layers.3.self_attn.v_proj.weight', 'graph_encoder.layers.3.self_attn_layer_norm.bias', 'graph_encoder.layers.3.self_attn_layer_norm.weight', 'graph_encoder.layers.4.fc1.bias', 'graph_encoder.layers.4.fc1.weight', 'graph_encoder.layers.4.fc2.bias', 'graph_encoder.layers.4.fc2.weight', 'graph_encoder.layers.4.final_layer_norm.bias', 'graph_encoder.layers.4.final_layer_norm.weight', 'graph_encoder.layers.4.self_attn.k_proj.bias', 'graph_encoder.layers.4.self_attn.k_proj.weight', 'graph_encoder.layers.4.self_attn.out_proj.bias', 'graph_encoder.layers.4.self_attn.out_proj.weight', 'graph_encoder.layers.4.self_attn.q_proj.bias', 'graph_encoder.layers.4.self_attn.q_proj.weight', 'graph_encoder.layers.4.self_attn.v_proj.bias', 'graph_encoder.layers.4.self_attn.v_proj.weight', 'graph_encoder.layers.4.self_attn_layer_norm.bias', 'graph_encoder.layers.4.self_attn_layer_norm.weight', 'graph_encoder.layers.5.fc1.bias', 'graph_encoder.layers.5.fc1.weight', 'graph_encoder.layers.5.fc2.bias', 'graph_encoder.layers.5.fc2.weight', 'graph_encoder.layers.5.final_layer_norm.bias', 'graph_encoder.layers.5.final_layer_norm.weight', 'graph_encoder.layers.5.self_attn.k_proj.bias', 'graph_encoder.layers.5.self_attn.k_proj.weight', 'graph_encoder.layers.5.self_attn.out_proj.bias', 'graph_encoder.layers.5.self_attn.out_proj.weight', 'graph_encoder.layers.5.self_attn.q_proj.bias', 'graph_encoder.layers.5.self_attn.q_proj.weight', 'graph_encoder.layers.5.self_attn.v_proj.bias', 'graph_encoder.layers.5.self_attn.v_proj.weight', 'graph_encoder.layers.5.self_attn_layer_norm.bias', 'graph_encoder.layers.5.self_attn_layer_norm.weight', 'graph_encoder.layers.6.fc1.bias', 'graph_encoder.layers.6.fc1.weight', 'graph_encoder.layers.6.fc2.bias', 'graph_encoder.layers.6.fc2.weight', 'graph_encoder.layers.6.final_layer_norm.bias', 'graph_encoder.layers.6.final_layer_norm.weight', 'graph_encoder.layers.6.self_attn.k_proj.bias', 'graph_encoder.layers.6.self_attn.k_proj.weight', 'graph_encoder.layers.6.self_attn.out_proj.bias', 'graph_encoder.layers.6.self_attn.out_proj.weight', 'graph_encoder.layers.6.self_attn.q_proj.bias', 'graph_encoder.layers.6.self_attn.q_proj.weight', 'graph_encoder.layers.6.self_attn.v_proj.bias', 'graph_encoder.layers.6.self_attn.v_proj.weight', 'graph_encoder.layers.6.self_attn_layer_norm.bias', 'graph_encoder.layers.6.self_attn_layer_norm.weight', 'graph_encoder.layers.7.fc1.bias', 'graph_encoder.layers.7.fc1.weight', 'graph_encoder.layers.7.fc2.bias', 'graph_encoder.layers.7.fc2.weight', 'graph_encoder.layers.7.final_layer_norm.bias', 'graph_encoder.layers.7.final_layer_norm.weight', 'graph_encoder.layers.7.self_attn.k_proj.bias', 'graph_encoder.layers.7.self_attn.k_proj.weight', 'graph_encoder.layers.7.self_attn.out_proj.bias', 'graph_encoder.layers.7.self_attn.out_proj.weight', 'graph_encoder.layers.7.self_attn.q_proj.bias', 'graph_encoder.layers.7.self_attn.q_proj.weight', 'graph_encoder.layers.7.self_attn.v_proj.bias', 'graph_encoder.layers.7.self_attn.v_proj.weight', 'graph_encoder.layers.7.self_attn_layer_norm.bias', 'graph_encoder.layers.7.self_attn_layer_norm.weight', 'graph_encoder.layers.8.fc1.bias', 'graph_encoder.layers.8.fc1.weight', 'graph_encoder.layers.8.fc2.bias', 'graph_encoder.layers.8.fc2.weight', 'graph_encoder.layers.8.final_layer_norm.bias', 'graph_encoder.layers.8.final_layer_norm.weight', 'graph_encoder.layers.8.self_attn.k_proj.bias', 'graph_encoder.layers.8.self_attn.k_proj.weight', 'graph_encoder.layers.8.self_attn.out_proj.bias', 'graph_encoder.layers.8.self_attn.out_proj.weight', 'graph_encoder.layers.8.self_attn.q_proj.bias', 'graph_encoder.layers.8.self_attn.q_proj.weight', 'graph_encoder.layers.8.self_attn.v_proj.bias', 'graph_encoder.layers.8.self_attn.v_proj.weight', 'graph_encoder.layers.8.self_attn_layer_norm.bias', 'graph_encoder.layers.8.self_attn_layer_norm.weight', 'graph_encoder.layers.9.fc1.bias', 'graph_encoder.layers.9.fc1.weight', 'graph_encoder.layers.9.fc2.bias', 'graph_encoder.layers.9.fc2.weight', 'graph_encoder.layers.9.final_layer_norm.bias', 'graph_encoder.layers.9.final_layer_norm.weight', 'graph_encoder.layers.9.self_attn.k_proj.bias', 'graph_encoder.layers.9.self_attn.k_proj.weight', 'graph_encoder.layers.9.self_attn.out_proj.bias', 'graph_encoder.layers.9.self_attn.out_proj.weight', 'graph_encoder.layers.9.self_attn.q_proj.bias', 'graph_encoder.layers.9.self_attn.q_proj.weight', 'graph_encoder.layers.9.self_attn.v_proj.bias', 'graph_encoder.layers.9.self_attn.v_proj.weight', 'graph_encoder.layers.9.self_attn_layer_norm.bias', 'graph_encoder.layers.9.self_attn_layer_norm.weight', 'layer_norm.bias', 'layer_norm.weight', 'lm_head_transform_weight.bias', 'lm_head_transform_weight.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# interact_model.load_state_dict(torch.load('/content/drive/MyDrive/results_epoch16.pt', map_location=torch.device('cpu')))","metadata":{"id":"uQG1_WBZkf32"},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# pip install wandb","metadata":{"id":"jm26QfVi2FEE","execution":{"iopub.status.busy":"2024-04-01T09:22:52.906063Z","iopub.execute_input":"2024-04-01T09:22:52.906897Z","iopub.status.idle":"2024-04-01T09:22:52.910886Z","shell.execute_reply.started":"2024-04-01T09:22:52.906855Z","shell.execute_reply":"2024-04-01T09:22:52.909989Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.init(\n    # set the wandb project where this run will be logged\n    project=\"kadduformer\",\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["e241a04638334d6bbf1e1aadc1cde2ef","f78c6a8c9d414fc9b2473dd5ceb1617c","d46726082701464cad2038962dbfb042","dcf20f96bcf34faeac3ace17c1f8b64b","5da99887c1a0406bbd341cd97f91f683","3ba86d2f2b434315903f3779600320ba","a4e1ad2eb0064d988f059afc55ade771","8b97859387db460ea82cbd672f394c26"]},"id":"nXrogYfLghtJ","outputId":"573e1866-b84b-4782-b68e-31f05f9e05c1","execution":{"iopub.status.busy":"2024-04-01T13:10:42.592494Z","iopub.execute_input":"2024-04-01T13:10:42.592847Z","iopub.status.idle":"2024-04-01T13:11:19.922964Z","shell.execute_reply.started":"2024-04-01T13:10:42.592818Z","shell.execute_reply":"2024-04-01T13:11:19.921918Z"},"trusted":true},"execution_count":322,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:1fug9n31) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f55ea7a0d0341cc8c5c6f011876fcd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>▇█▁▃</td></tr><tr><td>avg_train_loss</td><td>█▄▂▁</td></tr><tr><td>epoch</td><td>▁▁▃▃▆▆██</td></tr><tr><td>training_loss</td><td>█▆▄▂▅▄▅▄▄▂▂▃▄▄▅▆▃▃▃▄▃▃▃▅▂▃▁▁▂▃▁▃▄▃▂▁▄▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>0.17928</td></tr><tr><td>avg_train_loss</td><td>0.16118</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>training_loss</td><td>0.18538</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">morning-wood-84</strong> at: <a href='https://wandb.ai/mkr6255/kadduformer/runs/1fug9n31' target=\"_blank\">https://wandb.ai/mkr6255/kadduformer/runs/1fug9n31</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240401_092310-1fug9n31/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:1fug9n31). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240401_131042-hbrvso81</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mkr6255/kadduformer/runs/hbrvso81' target=\"_blank\">bright-sun-85</a></strong> to <a href='https://wandb.ai/mkr6255/kadduformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mkr6255/kadduformer' target=\"_blank\">https://wandb.ai/mkr6255/kadduformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mkr6255/kadduformer/runs/hbrvso81' target=\"_blank\">https://wandb.ai/mkr6255/kadduformer/runs/hbrvso81</a>"},"metadata":{}},{"execution_count":322,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mkr6255/kadduformer/runs/hbrvso81?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7f468e8934c0>"},"metadata":{}}]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"ZPli0y2USMp3"},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef calculate_pos_weights(num_positives, num_negatives):\n  \"\"\"\n  Calculates class weight for positive class in binary crossentropy with logits loss.\n\n  Args:\n      num_positives: int Number of positive samples.\n      num_negatives: int Number of negative samples.\n\n  Returns:\n      float Class weight for the positive class.\n  \"\"\"\n  if num_positives == 0:\n    raise ValueError(\"Number of positive samples cannot be zero.\")\n  pos_weight = num_negatives / num_positives\n  return pos_weight\n\n# Example usage\nnum_positives = 3754\nnum_negatives = 33918\npos_weight = calculate_pos_weights(num_positives, num_negatives)\nprint(pos_weight)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ex2hf_QxghtJ","outputId":"8921abae-edd1-475a-82fb-1d776f3f6bad","execution":{"iopub.status.busy":"2024-04-01T13:11:19.924767Z","iopub.execute_input":"2024-04-01T13:11:19.925372Z","iopub.status.idle":"2024-04-01T13:11:19.933765Z","shell.execute_reply.started":"2024-04-01T13:11:19.925335Z","shell.execute_reply":"2024-04-01T13:11:19.932756Z"},"trusted":true},"execution_count":323,"outputs":[{"name":"stdout","text":"9.035162493340437\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import StepLR\n# weight = torch.tensor()\noptimizer = optim.Adam(interact_model.parameters(), lr=3e-5,weight_decay=1e-5)\n\n# Move model to device if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.BCELoss()#BCEWithLogitsLoss()#(pos_weight = torch.tensor([.9035162493340437]).to(device))#(weight=torch.tensor([0.09964960713527288]))#(pos_weight = torch.tensor([0.09964960713527288]))  # Binary Cross-Entropy Loss\n\ninteract_model.to(device)\ntrain_dataloader=train_loader\n# Training loop\nprint_frequency = 1000\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR by a factor of 0.1 every 5 epochs\nepochs = 4\n\nfor epoch in range(epochs):\n    interact_model.train()\n    total_loss = 0\n    correct_predictions = 0\n    total_samples = 0\n    step_counter = 0\n    running_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n#         if step_counter<20:\n            try:\n\n                optimizer.zero_grad()\n                inputs, labels = batch.to(device),torch.tensor(batch['y'], dtype=torch.float).squeeze(1).to(device)\n\n                # Forward pass\n                outputs = interact_model(inputs)\n#                 print(outputs[0])\n#                 print(labels) # Remove the second dimension\n                loss = criterion(outputs[0], labels)\n                total_loss += loss.item()\n                running_loss +=loss.item()\n        #             grads = torch.autograd.grad(outputs=outputs, inputs=inputs, grad_outputs=torch.ones_like(outputs), allow_unused=True)\n\n                loss.backward()\n                  # Monitor gradients\n                optimizer.step()\n\n                step_counter += 1\n\n                if step_counter % print_frequency == 0:\n                    epoch_loss = total_loss / print_frequency  # Calculate average loss for the last print_frequency steps\n                    print(f\"output:{outputs.float().to(device)} , act: {labels.float()}\")  # Calculate average loss for the last print_frequency steps\n                    print(\"loss::::::::::::::::::::\",epoch_loss)\n                    wandb.log({\"training_loss\": epoch_loss})\n\n                    total_loss = 0  # Reset total loss after printing\n            except:\n#                 print('error')\n                pass\n\n    scheduler.step()\n# Compute average training loss for the epoch\n    avg_train_loss = running_loss / len(train_loader)\n\n    # Log average training loss for the epoch\n    wandb.log({\"epoch\": epoch, \"avg_train_loss\": avg_train_loss})\n\n    # Set model to evaluation mode\n    interact_model.eval()\n\n    # Evaluate on test data loader\n    test_loss = 0.0\n    with torch.no_grad():\n        for test_batch in test_loader:\n            try:\n                inputs, labels = test_batch.to(device),torch.tensor(test_batch['y'], dtype=torch.float).squeeze(0).to(device)\n                output = interact_model(inputs)\n                test_loss += criterion(output[0], labels).item()\n            except:\n                pass\n    avg_test_loss = test_loss / len(test_loader)\n\n    # Log test loss for the epoch\n    wandb.log({\"epoch\": epoch, \"avg_test_loss\": avg_test_loss})\n\n    # Set model back to training mode\n    interact_model.train()\n\n    # Print epoch results\n    torch.save(interact_model.state_dict(), f\"results_epoch{epoch}.pt\")\n    print(f'Epoch {epoch + 1}, Avg. Training Loss: {avg_train_loss}, Avg. Test Loss: {avg_test_loss}')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"BHQ0v4GBghtK","outputId":"5d0be4c1-54a0-4116-f7ce-bc7a2a8075cf","scrolled":true,"execution":{"iopub.status.busy":"2024-04-01T13:12:09.767076Z","iopub.execute_input":"2024-04-01T13:12:09.767448Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1/4:   0%|          | 0/33841 [00:00<?, ?it/s]/tmp/ipykernel_34/3446899099.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs, labels = batch.to(device),torch.tensor(batch['y'], dtype=torch.float).squeeze(1).to(device)\n/tmp/ipykernel_34/4018292533.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  graph_rep, _ = self.graph_encoder(torch.tensor(inputs['input_nodes']), torch.tensor(inputs['input_edges']), torch.tensor(inputs['attn_bias']), torch.tensor(inputs['in_degree']), torch.tensor(inputs['out_degree']), torch.tensor(inputs['spatial_pos']), torch.tensor(inputs['attn_edge_type']))\nEpoch 1/4:   3%|▎         | 1002/33841 [01:17<46:29, 11.77it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0306]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.28899315743305487\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:   6%|▌         | 2002/33841 [02:37<42:59, 12.34it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0003]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.23086554735901882\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:   9%|▉         | 3001/33841 [04:01<42:33, 12.08it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1852]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.23945683776495572\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  12%|█▏        | 4001/33841 [05:21<38:49, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0005]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19974208805931265\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  15%|█▍        | 5001/33841 [06:40<38:21, 12.53it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0042]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19034314837081365\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  18%|█▊        | 6001/33841 [08:00<37:24, 12.40it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0001]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1770724367986186\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  21%|██        | 7001/33841 [09:20<35:56, 12.45it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0029]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.2803094615686805\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  24%|██▎       | 8003/33841 [10:41<34:31, 12.48it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1995]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1970541564737505\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  27%|██▋       | 9003/33841 [12:00<33:18, 12.43it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0644]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.184112429039189\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  30%|██▉       | 10003/33841 [13:20<31:58, 12.43it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0127]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18978122478858223\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  33%|███▎      | 11003/33841 [14:41<30:36, 12.44it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0726]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19303592819990445\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  35%|███▌      | 12003/33841 [16:02<29:23, 12.38it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[5.2119e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18381011885594306\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  38%|███▊      | 13003/33841 [17:22<27:37, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[3.5019e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17497683089721922\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  41%|████▏     | 14003/33841 [18:42<27:02, 12.22it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0693]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19343094325434548\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  44%|████▍     | 15003/33841 [20:02<26:29, 11.85it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[3.3437e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18123023134700997\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  47%|████▋     | 16003/33841 [21:22<24:05, 12.34it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.7793e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18847192206709962\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  50%|█████     | 17003/33841 [22:43<22:35, 12.42it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1714]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17991702344754795\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  53%|█████▎    | 18003/33841 [24:03<20:59, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1068]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1844886033937263\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  56%|█████▌    | 19003/33841 [25:24<20:05, 12.31it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[4.1476e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16198911218967244\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  59%|█████▉    | 20003/33841 [26:46<18:37, 12.39it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[5.1446e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.22525725162866087\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  62%|██████▏   | 21003/33841 [28:09<18:44, 11.42it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0003]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1853877426605261\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  65%|██████▌   | 22003/33841 [29:33<16:23, 12.04it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[3.9396e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16580614396942125\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  68%|██████▊   | 23003/33841 [30:57<14:36, 12.37it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.2205]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.15777711342761525\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  71%|███████   | 24003/33841 [32:17<13:11, 12.43it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0020]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19008740424143664\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  74%|███████▍  | 25003/33841 [33:38<11:55, 12.35it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.2095]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17746277367102906\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  77%|███████▋  | 26003/33841 [34:58<10:32, 12.39it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.2327e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17895224616343938\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  80%|███████▉  | 27003/33841 [36:20<09:18, 12.24it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[3.0391e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18863658782997875\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  83%|████████▎ | 28003/33841 [37:41<07:51, 12.38it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1562]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17717235386292762\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  86%|████████▌ | 29003/33841 [39:02<06:38, 12.13it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0145]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.2630529742764827\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  89%|████████▊ | 30003/33841 [40:23<05:11, 12.33it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0014]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.26020559722435793\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  92%|█████████▏| 31003/33841 [41:44<03:48, 12.41it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.3075]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.20033519974331465\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  95%|█████████▍| 32003/33841 [43:06<02:27, 12.50it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.8320e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.21487589402871704\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:  98%|█████████▊| 33003/33841 [44:25<01:06, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1143]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16412527432325708\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4: 100%|██████████| 33841/33841 [45:33<00:00, 12.38it/s]\n/tmp/ipykernel_34/3446899099.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs, labels = test_batch.to(device),torch.tensor(test_batch['y'], dtype=torch.float).squeeze(0).to(device)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Avg. Training Loss: 0.19914906283285494, Avg. Test Loss: 0.2000404862183853\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:   3%|▎         | 1002/33841 [01:22<45:19, 12.08it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[7.7020e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17366940645477275\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:   6%|▌         | 2002/33841 [02:43<43:32, 12.19it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.2808]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19869831997032292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:   9%|▉         | 3002/33841 [04:04<41:32, 12.37it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[9.3317e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1722705922673131\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  12%|█▏        | 4002/33841 [05:26<41:43, 11.92it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.5437e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16535332440739103\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  15%|█▍        | 5002/33841 [06:47<39:28, 12.17it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.0386e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1771968226296371\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  18%|█▊        | 6002/33841 [08:09<38:07, 12.17it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.0103e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17662593418531897\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  21%|██        | 7002/33841 [09:29<36:19, 12.31it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0003]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.2156088676443268\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  24%|██▎       | 8002/33841 [10:50<34:33, 12.46it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0374]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16952918147478832\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  27%|██▋       | 9002/33841 [12:12<36:37, 11.30it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1140]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18669662088068953\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  30%|██▉       | 10002/33841 [13:32<32:03, 12.39it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.7749e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19555586908869732\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  33%|███▎      | 11002/33841 [14:53<30:17, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.3101e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18792190012013496\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  35%|███▌      | 12002/33841 [16:13<29:23, 12.38it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.5959e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17220350378947338\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  38%|███▊      | 13002/33841 [17:33<27:41, 12.54it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1920]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.18068313671075845\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  41%|████▏     | 14002/33841 [18:53<26:56, 12.27it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[4.9485e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19392954441837412\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  44%|████▍     | 15002/33841 [20:14<24:58, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[3.6275e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16863292359433787\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  47%|████▋     | 16002/33841 [21:34<25:06, 11.84it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1121]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17373230645754195\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  50%|█████     | 17002/33841 [22:53<22:18, 12.58it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0772]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16651323906533166\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  53%|█████▎    | 18002/33841 [24:13<20:58, 12.58it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0020]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.21187723285792553\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  56%|█████▌    | 19002/33841 [25:33<19:51, 12.45it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1839]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.17468449155991947\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  59%|█████▉    | 20002/33841 [26:53<18:07, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0004]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17004129168680673\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  62%|██████▏   | 21002/33841 [28:12<17:05, 12.52it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0017]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17800349857406764\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  65%|██████▌   | 22002/33841 [29:31<15:44, 12.54it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.9953e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1630981792574248\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  68%|██████▊   | 23002/33841 [30:50<14:08, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1048]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17810798845315293\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  71%|███████   | 24002/33841 [32:10<13:15, 12.36it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[4.3650e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1616611392503225\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  74%|███████▍  | 25002/33841 [33:29<11:38, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.2113e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16185795263624692\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  77%|███████▋  | 26002/33841 [34:48<10:16, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.6747e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.2063555211873662\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  80%|███████▉  | 27003/33841 [36:07<09:41, 11.77it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1031]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.19146789046463267\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  83%|████████▎ | 28003/33841 [37:26<07:48, 12.45it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.7595e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.14636645209318314\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  86%|████████▌ | 29003/33841 [38:46<06:32, 12.31it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1635]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18321870931097534\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  89%|████████▊ | 30003/33841 [40:05<05:12, 12.27it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.1663e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16268194974212435\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  92%|█████████▏| 31003/33841 [41:24<03:44, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1952]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1865305948090127\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  95%|█████████▍| 32003/33841 [42:43<02:26, 12.52it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0862]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.14893136887379854\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4:  98%|█████████▊| 33003/33841 [44:03<01:07, 12.42it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.3871]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19639142544788007\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4: 100%|██████████| 33841/33841 [45:10<00:00, 12.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Avg. Training Loss: 0.1786566185264126, Avg. Test Loss: 0.1830154994647529\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:   3%|▎         | 1002/33841 [01:19<43:18, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.4563e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18226591613080245\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:   6%|▌         | 2002/33841 [02:37<41:48, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9861]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.17891981050053235\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:   9%|▉         | 3002/33841 [03:57<42:03, 12.22it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[9.4076e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.16852964081487634\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  12%|█▏        | 4002/33841 [05:17<41:22, 12.02it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0357]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.2213666052445679\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  15%|█▍        | 5002/33841 [06:35<40:00, 12.01it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0616]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.17256719531585862\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  18%|█▊        | 6002/33841 [07:55<36:28, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9999]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.1762898229133179\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  21%|██        | 7002/33841 [09:14<34:34, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1221]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19112146751240672\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  24%|██▎       | 8002/33841 [10:32<33:46, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9870]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.17714506876858876\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  27%|██▋       | 9002/33841 [11:51<37:00, 11.19it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0275]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.14821139872583114\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  30%|██▉       | 10002/33841 [13:11<30:48, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[2.6409e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19450659730979544\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  33%|███▎      | 11002/33841 [14:29<29:46, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0140]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.18891859438414013\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  35%|███▌      | 12002/33841 [15:47<29:41, 12.26it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.0770]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.18160636566121013\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  38%|███▊      | 13003/33841 [17:05<27:15, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.2094]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.1506111251471138\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  41%|████▏     | 14003/33841 [18:22<25:30, 12.96it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.2168]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.16284709126989008\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  44%|████▍     | 15003/33841 [19:40<24:34, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9956]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.18013673903771368\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  47%|████▋     | 16003/33841 [20:57<23:18, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[4.0568e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.15164019790923844\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  50%|█████     | 17003/33841 [22:15<22:17, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[1.0021e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17187048940252925\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  53%|█████▎    | 18003/33841 [23:32<20:21, 12.97it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9917]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.1695408259077716\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  56%|█████▌    | 19003/33841 [24:49<19:03, 12.97it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9901]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.1297496743509777\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  59%|█████▉    | 20004/33841 [26:07<18:06, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1236]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.17489157674050204\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  62%|██████▏   | 21004/33841 [27:25<16:31, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.1954]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.15436210093912023\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  65%|██████▌   | 22004/33841 [28:43<15:15, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.2423]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.162468820981452\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  68%|██████▊   | 23004/33841 [30:03<14:29, 12.47it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[0.9542]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([1.], device='cuda:0')\nloss:::::::::::::::::::: 0.17730856279509224\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  71%|███████   | 24004/33841 [31:22<12:46, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"output:tensor([[3.3140e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>) , act: tensor([0.], device='cuda:0')\nloss:::::::::::::::::::: 0.19389816702651352\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4:  73%|███████▎  | 24650/33841 [32:12<11:44, 13.05it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"0hIJLTWXghtW"},"execution_count":null,"outputs":[]}]}